import numpy as np
import tensorflow as tf
import matplotlib.pyplot as plt
from tensorflow.keras.preprocessing.sequence import pad_sequences
from tensorflow.keras.datasets import imdb
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Embedding, SimpleRNN, Dense, Dropout
from tensorflow.keras.optimizers import Adam

# Load data
num_words = 10000  # Using top 10,000 most frequent words
(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=num_words)

# Pad sequences to ensure uniform input size
maxlen = 500  # Maximum length of review (in words)
x_train = pad_sequences(x_train, maxlen=maxlen)
x_test = pad_sequences(x_test, maxlen=maxlen)

# Build the model
model = Sequential()
model.add(Embedding(input_dim=num_words, output_dim=128, input_shape=(maxlen,)))  # Fixed here
model.add(SimpleRNN(128, return_sequences=False, dropout=0.2, recurrent_dropout=0.2))  # Simple RNN layer
model.add(Dense(1, activation='sigmoid'))  # Output layer with sigmoid activation (binary classification)

# Compile the model
model.compile(optimizer=Adam(), loss='binary_crossentropy', metrics=['accuracy'])

# Train the model
history = model.fit(x_train, y_train, epochs=5, batch_size=64, validation_data=(x_test, y_test))

# Model Summary
model.summary()

# Plot Training and Validation Accuracy & Loss
plt.figure(figsize=(12, 6))

# Accuracy Plot
plt.subplot(1, 2, 1)
plt.plot(history.history['accuracy'], label='Training Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()

# Loss Plot
plt.subplot(1, 2, 2)
plt.plot(history.history['loss'], label='Training Loss')
plt.plot(history.history['val_loss'], lamnbel='Validation Loss')
plt.title('Training and Validation Loss')
plt.xlabel('Epochs')
plt.ylabel('Loss')
plt.legend()

plt.tight_layout()
plt.show()

# Evaluate the model
test_loss, test_accuracy = model.evaluate(x_test, y_test)
print(f"Test Loss: {test_loss}")
print(f"Test Accuracy: {test_accuracy}")

# Sentiment prediction function
def predict_sentiment(review, maxlen=maxlen):
    # Tokenize the review by the vocabulary index in IMDB
    tokenizer = imdb.get_word_index()  # Get word index for IMDB dataset
    review_sequence = [[tokenizer.get(word, 0) for word in review.lower().split()]]  # Convert words to indices
    review_padded = pad_sequences(review_sequence, maxlen=maxlen)  # Pad sequence to match model input shape
    prediction = model.predict(review_padded)  # Predict sentiment (0 or 1)
    return 'Positive' if prediction > 0.5 else 'Negative'

# Example review for prediction
review = "This movie was amazing! The plot and acting were great."
print(f"Review: {review}")
print(f"Predicted Sentiment: {predict_sentiment(review)}")

